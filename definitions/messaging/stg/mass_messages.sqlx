config {
  type: "incremental",
  schema: "eros_messaging_stg", 
  uniqueKey: ["message_sk"],
  partitionBy: "sending_date",
  clusterBy: ["username_std"],
  requirePartitionFilter: true,
  description: "Incremental mass messages with 14-day watermark",
  labels: {app: "eros", domain: "messaging", layer: "stg"},
  tags: ["messaging_stg"]
}

WITH 
historical_source AS (
  -- Standardize the historical (facts) data to consistent types first
  SELECT
    CAST(message_id AS STRING) as message_id,
    CAST(sender AS STRING) as sender,
    CAST(sending_time AS STRING) as sending_time,
    CAST(price AS STRING) as price,
    SAFE_CAST(sent AS INT64) as sent,
    SAFE_CAST(viewed AS INT64) as viewed,
    SAFE_CAST(purchased AS INT64) as purchased,
    CAST(earnings AS STRING) as earnings,
    message as message_text,
    'historical' as source_file
  FROM ${ref("facts_messages_all")}
),

daily_source AS (
  -- Standardize the daily data to the same consistent types
  SELECT
    CAST(message_id AS STRING) as message_id,
    CAST(sender AS STRING) as sender,
    CAST(sending_time AS STRING) as sending_time,
    CAST(price AS STRING) as price,
    SAFE_CAST(sent AS INT64) as sent,
    SAFE_CAST(viewed AS INT64) as viewed,
    SAFE_CAST(purchased AS INT64) as purchased,
    CAST(earnings AS STRING) as earnings,
    message_text,
    'daily' as source_file
  FROM ${ref("mass_message_daily_final")}
),

messages_unioned AS (
  -- Now that schemas are identical, the UNION will work reliably
  SELECT * FROM historical_source
  UNION ALL
  SELECT * FROM daily_source
),

messages_cleaned AS (
  -- Perform final parsing on the clean, unified data
  SELECT
    FARM_FINGERPRINT(CONCAT(message_id, '_', source_file)) as message_sk,
    LOWER(TRIM(sender)) as username_std,
    COALESCE(
      SAFE.PARSE_TIMESTAMP('%Y-%m-%dT%H:%M:%E*S%Ez', sending_time),
      SAFE.PARSE_TIMESTAMP('%Y-%m-%d %H:%M:%S', sending_time)
    ) as sending_ts,
    SAFE_CAST(REGEXP_REPLACE(price, r'[$,]', '') AS FLOAT64) as price,
    sent as sent_count,
    viewed as viewed_count,
    purchased as purchased_count, 
    SAFE_CAST(REGEXP_REPLACE(earnings, r'[$,]', '') AS FLOAT64) as earnings_total,
    message_text,
    source_file,
    CURRENT_TIMESTAMP() as loaded_at
  FROM messages_unioned
),

messages_final AS (
  SELECT
    *,
    DATE(sending_ts) as sending_date
  FROM messages_cleaned
  WHERE sending_ts IS NOT NULL
)

SELECT * FROM messages_final
WHERE sending_date >= '2024-01-01'
  
${ when(incremental(), `
  AND sending_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 14 DAY)
  AND sending_ts > (SELECT MAX(sending_ts) FROM ${self()})
`) }

QUALIFY ROW_NUMBER() OVER (
  PARTITION BY message_sk 
  ORDER BY loaded_at DESC
) = 1
